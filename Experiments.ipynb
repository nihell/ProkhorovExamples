{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15961f45-3f99-49c8-9d53-f0bf5f937ec9",
   "metadata": {},
   "source": [
    "### Experiments for Prokhorov Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfb638e-abe0-4ba4-bdfc-8419e4d17ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import gudhi as gd\n",
    "from gudhi import hera\n",
    "from gudhi import representations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn import manifold\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.optimize as spo \n",
    "from scipy.optimize import minimize\n",
    "import kmedoids\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5da1a-42b2-4774-9937-0cea5a4501bd",
   "metadata": {},
   "source": [
    "Some functions to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1be77b-088c-45d4-9189-344820893008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diag_to_array(data):\n",
    "    dataset, num_diag = [], len(data[\"0\"].keys())\n",
    "    for dim in data.keys():\n",
    "        X = []\n",
    "        for diag in range(num_diag):\n",
    "            pers_diag = np.array(data[dim][str(diag)])\n",
    "            X.append(pers_diag)\n",
    "        dataset.append(X)\n",
    "    return dataset\n",
    "\n",
    "def diag_to_dict(D):\n",
    "    X = dict()\n",
    "    for f in D.keys():\n",
    "        df = diag_to_array(D[f])\n",
    "        for dim in range(len(df)):\n",
    "            X[str(dim) + \"_\" + f] = df[dim]\n",
    "    return X \n",
    "\n",
    "def load_PI_data(dim = \"1\", noise = \"1\"):\n",
    "    path = \"../PersistenceImages/matlab_code/sixShapeClasses/ToyData_PD_TextFiles/\"\n",
    "    PDs = {}\n",
    "    for entry in os.scandir(path):\n",
    "        if(entry.name.endswith(\".txt\")):\n",
    "            PDs[entry.name] = {\"noise\":entry.name.split(sep=\"_\")[2],\n",
    "                               \"index\":entry.name.split(sep=\"_\")[3],\n",
    "                               \"shape_class\":entry.name.split(sep=\"_\")[4],\n",
    "                               \"dimension\":entry.name.split(sep=\"_\")[5],\n",
    "                               \"data\":np.loadtxt(entry.path)}\n",
    "    persistence_list = [pd[\"data\"] for pd in PDs.values() if(pd[\"noise\"]==\"n{}\".format(noise) and pd[\"dimension\"]==\"{}.txt\".format(dim))]\n",
    "    labels = [pd[\"shape_class\"] for pd in PDs.values() if(pd[\"noise\"]==\"n{}\".format(noise) and pd[\"dimension\"]==\"{}.txt\".format(dim))]\n",
    "    return persistence_list, labels\n",
    "\n",
    "def load_3d_data():\n",
    "    path = \"../sklearn-tda/example/3DSeg/\"\n",
    "    train_lab  = pd.read_csv(path+\"train.csv\")\n",
    "    train_diag = diag_to_dict(h5py.File(path+\"train_diag.hdf5\", \"r\"))\n",
    "    return train_diag, train_lab\n",
    "\n",
    "def load_cubical_data(filt=\"upper\", d=1):\n",
    "    f= h5py.File('cubical_data_{}_{}d.hdf5'.format(filt,d), \"r\")[\"list_of_lists\"]\n",
    "    X = []\n",
    "    for i in range(0,len(f)):\n",
    "        X.append(np.array(f[str(i)]))\n",
    "    y = np.loadtxt('cubical_labels_{}_{}d.txt'.format(filt,d), dtype = int)\n",
    "    return np.array(X),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94bb247-cc99-427c-9d5a-d80e25927685",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_PI_data(dim=\"1\", noise=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d98e647-36a9-4209-bc77-5e1d647d9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae33834-2146-477c-8762-1a66653980ed",
   "metadata": {},
   "source": [
    "## K-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1550a300-389e-495b-bc92-b9ac7c31cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric = \"precomputed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861622c3-31b8-4bf6-b645-1d6512b35a9f",
   "metadata": {},
   "source": [
    "Perform a grid search with cross-validation among integer slopes for the Prokhorov parameter function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d0309-c173-46bb-8bd7-ba669b9c2e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09aeac7be3f41b48dc8ea176d04c7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_params = range(10,100)\n",
    "best_param = 0\n",
    "best_score = 0\n",
    "\n",
    "tic = time.time()\n",
    "for p in tqdm(list_of_params):\n",
    "    PD = gd.representations.ProkhorovDistance(n_jobs = -1, coefs = np.array([0,p]))\n",
    "    PD.fit(X_train)\n",
    "    P_train = PD.transform(X_train)\n",
    "    cv_scores = cross_val_score(knn, P_train, y_train, cv=5)\n",
    "    if np.mean(cv_scores)>best_score:\n",
    "        best_param = p\n",
    "        best_score = np.mean(cv_scores)\n",
    "        \n",
    "print(\"grid search completed in {}s, best parameter is {} with score {}\".format(time.time()-tic, best_param, best_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cecc03-b8dd-4813-8607-ebb4bbf5b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = [gd.representations.ProkhorovDistance(n_jobs=-1, coefs = np.array([0,best_param])),\n",
    "        gd.representations.BottleneckDistance(n_jobs=-1),\n",
    "        gd.representations.WassersteinDistance(n_jobs=-1, order=1, internal_p =1),\n",
    "        gd.representations.WassersteinDistance(n_jobs=-1, order=2, internal_p =2)]\n",
    "\n",
    "for r in reps:\n",
    "    print(\"------------------\"+str(r)+\"------------------\")\n",
    "    tic = time.time()\n",
    "    r.fit(X_train)\n",
    "    D_matrix_train = r.transform(X_train)\n",
    "    D_matrix_test = r.transform(X_test)\n",
    "    print(\"distance computation done in \", time.time()-tic)\n",
    "    cv_scores = cross_val_score(knn, D_matrix_train, y_train, cv=5)\n",
    "    print(\"training accuracy: \",np.mean(cv_scores))\n",
    "    knn.fit(D_matrix_train, y_train)\n",
    "    score = knn.score(D_matrix_test, y_test)\n",
    "    print(\"test accuracy: \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bee447-be6d-4b6d-8be1-e49d4c01e3c3",
   "metadata": {},
   "source": [
    "## K-Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ff515-ac26-4813-a33c-3164e55e6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = kmedoids.KMedoids(n_clusters = len(np.unique(y)), metric=\"precomputed\", init = \"build\", random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60ebdd-fb49-4e87-9a78-feb65aa6a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_info(cluster_labels,y_train):\n",
    "    # Initializing\n",
    "    reference_labels = {}\n",
    "    # For loop to run through each label of cluster label\n",
    "    for i in range(len(np.unique(cluster_labels))):\n",
    "        index = np.where(cluster_labels == i,1,0)\n",
    "        num = np.bincount(y_train[index==1]).argmax()\n",
    "        reference_labels[i] = num\n",
    "    return reference_labels\n",
    "\n",
    "def km_cv(km, rep, X, y, cv):\n",
    "    rs = ShuffleSplit(n_splits=cv, test_size=1.0/cv, random_state=0)\n",
    "    scores = []\n",
    "    for train_index, test_index in rs.split(X):\n",
    "        train_index = np.array(train_index)\n",
    "        test_index = np.array(test_index)\n",
    "        X_train_cv = X[train_index]\n",
    "        y_train_cv = y[train_index]\n",
    "        X_test_cv = X[test_index]\n",
    "        y_test_cv = y[test_index]\n",
    "        \n",
    "        rep.fit(X_train_cv)\n",
    "        km.fit(rep.transform(X_train_cv))\n",
    "        label_dictionary = retrieve_info(km.labels_, y_train_cv)\n",
    "        \n",
    "        predicted_clusters = km.predict(rep.transform(X_test_cv))\n",
    "        predicted_labels = [label_dictionary[predicted_clusters[i]] for i in range(0,len(predicted_clusters))]\n",
    "            \n",
    "        scores.append(accuracy_score(predicted_labels,y_test_cv))\n",
    "    \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bc341-3b4b-4371-8022-121e8c0007d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_params = range(10,100)\n",
    "best_param = 0\n",
    "best_score = 0\n",
    "\n",
    "tic = time.time()\n",
    "for p in tqdm(list_of_params):\n",
    "    PD = gd.representations.ProkhorovDistance(n_jobs = -1, coefs = np.array([0,p]))\n",
    "\n",
    "    cv_scores = km_cv(km, PD, X_train, y_train, 5)\n",
    "    if np.mean(cv_scores)>best_score:\n",
    "        best_param = p\n",
    "        best_score = np.mean(cv_scores)\n",
    "        \n",
    "print(\"grid search completed in {}s, best parameter is {} with score {}\".format(time.time()-tic, best_param, best_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07c651-43df-479b-a59a-2253f3789ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = [gd.representations.ProkhorovDistance(n_jobs=-1, coefs = np.array([0,26])),\n",
    "        gd.representations.BottleneckDistance(n_jobs=-1),\n",
    "        gd.representations.WassersteinDistance(n_jobs=-1, order=1, internal_p =1),\n",
    "        gd.representations.WassersteinDistance(n_jobs=-1, order=2, internal_p =2)]\n",
    "\n",
    "for r in reps:\n",
    "    print(\"------------------\"+str(r)+\"------------------\")\n",
    "    tic = time.time()\n",
    "    r.fit(X_train)\n",
    "    D_matrix_train = r.transform(X_train)\n",
    "    D_matrix_test = r.transform(X_test)\n",
    "    print(\"distance computation done in \", time.time()-tic)\n",
    "    cv_scores = km_cv(km, r, X_train, y_train, 5)\n",
    "    print(\"training accuracy: \",np.mean(cv_scores))\n",
    "    km.fit(D_matrix_train)\n",
    "    label_dictionary = retrieve_info(km.labels_, y_train)\n",
    "    predicted_clusters = km.predict(D_matrix_test)\n",
    "    predicted_labels = [label_dictionary[predicted_clusters[i]] for i in range(0,len(predicted_clusters))]\n",
    "    score = accuracy_score(predicted_labels,y_test)\n",
    "    print(\"test accuracy: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243f911-8580-4384-86a7-049196d1d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
